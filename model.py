# -*- coding: utf-8 -*-
"""MYMalariaCellCode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KUccB81rJTr4RlsejalczF3ZfbVHVDdA
"""

# Install PyTorch and torchvision
!pip install torch torchvision torchaudio

# Install Detectron2
!pip install 'detectron2@git+https://github.com/facebookresearch/detectron2.git'


# Install other required libraries
!pip install matplotlib scikit-learn pandas opencv-python

import os
import numpy as np
import torch
from tqdm import tqdm
import cv2
import random
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.utils.visualizer import Visualizer
from detectron2.utils.logger import setup_logger
from detectron2.data import DatasetCatalog, MetadataCatalog, DatasetMapper, build_detection_train_loader
from detectron2.structures import BoxMode
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

setup_logger()

from google.colab import drive

drive.mount("/content/drive", force_remount=True)

import json
import os

# Define paths
input_train_json = "/content/drive/MyDrive/ProjectMAL/training.json"
input_test_json = "/content/drive/MyDrive/ProjectMAL/test.json"
output_dir = "/content/malaria_dataset"
output_train_json = os.path.join(output_dir, "fixed_training.json")
output_test_json = os.path.join(output_dir, "fixed_test.json")

# Ensure output directory exists
os.makedirs(output_dir, exist_ok=True)

# Define category mapping
category_mapping = {
    "red blood cell": 1,
    "leukocyte": 2,
    "gametocyte": 3,
    "ring": 4,
    "trophozoite": 5,
    "schizont": 6,
    "difficult": 7  # Optional if needed
}

def convert_to_coco(input_json_path, output_json_path):
    """ Convert dataset JSON to COCO format """
    with open(input_json_path) as f:
        raw_data = json.load(f)

    # Initialize COCO format structure
    coco_format = {
        "images": [],
        "annotations": [],
        "categories": [{"id": cid, "name": name} for name, cid in category_mapping.items()]
    }

    annotation_id = 1  # Unique ID for each annotation

    for idx, entry in enumerate(raw_data):
        image_info = entry["image"]
        image_id = idx + 1  # Ensure unique image ID
        filename = os.path.basename(image_info["pathname"])

        # Add image metadata
        coco_format["images"].append({
            "id": image_id,
            "file_name": filename,
            "width": image_info["shape"]["c"],
            "height": image_info["shape"]["r"],
        })
        # Process bounding boxes
        for obj in entry["objects"]:
            category_name = obj["category"]
            if category_name not in category_mapping:
                continue  # Skip unknown categories

            category_id = category_mapping[category_name]

            # Convert min/max bounding box format to [x, y, width, height]
            min_x, min_y = obj["bounding_box"]["minimum"]["c"], obj["bounding_box"]["minimum"]["r"]
            max_x, max_y = obj["bounding_box"]["maximum"]["c"], obj["bounding_box"]["maximum"]["r"]
            bbox = [min_x, min_y, max_x - min_x, max_y - min_y]  # Convert to COCO bbox format

            # Add annotation
            coco_format["annotations"].append({
                "id": annotation_id,
                "image_id": image_id,
                "category_id": category_id,
                "bbox": bbox,
                "area": bbox[2] * bbox[3],  # Width * Height
                "segmentation": [],  # If you have mask annotations, add them here
                "iscrowd": 0
            })
            annotation_id += 1

    # Save the fixed JSON
    with open(output_json_path, "w") as f:
        json.dump(coco_format, f, indent=4)

    print(f"✅ Converted {input_json_path} → {output_json_path}")

# Convert both train & test datasets
convert_to_coco(input_train_json, output_train_json)
convert_to_coco(input_test_json, output_test_json)

import os

# Path to your image directory
image_dir = "/content/drive/MyDrive/ProjectMAL/images"

# List all files in the directory
image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

# Display the total number of images
print(f"✅ Total number of images: {len(image_files)}")

from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.data.datasets import register_coco_instances

# Dataset names
train_dataset_name = "malaria_train"
test_dataset_name = "malaria_test"

# Paths to annotation files and image directories
train_json = "/content/malaria_dataset/fixed_training.json"
train_images = "/content/drive/MyDrive/ProjectMAL/images"
test_json = "/content/malaria_dataset/fixed_test.json"
test_images = "/content/drive/MyDrive/ProjectMAL/test_images"

# Unregister datasets if already registered
for dataset_name in [train_dataset_name, test_dataset_name]:
    if dataset_name in DatasetCatalog.list():
        DatasetCatalog.remove(dataset_name)
        MetadataCatalog.pop(dataset_name)

# Register the datasets again
register_coco_instances(train_dataset_name, {}, train_json, train_images)
register_coco_instances(test_dataset_name, {}, test_json, test_images)

# Confirm successful registration
print("✅ Registered datasets:", DatasetCatalog.list())  # Should include 'malaria_train' and 'malaria_test'

from detectron2.data import DatasetCatalog

dataset_dicts = DatasetCatalog.get("malaria_train")
print(f"✅ Loaded {len(dataset_dicts)} samples from malaria_train dataset.")

"""# **Configuration Stage**"""

metadata = MetadataCatalog.get("malaria_train")
print("Categories in metadata:", metadata.thing_classes)

# Checking if all category IDs are valid
invalid_categories = []

for d in dataset_dicts:
    for ann in d["annotations"]:
        if ann["category_id"] >= len(metadata.thing_classes):
            invalid_categories.append(ann["category_id"])

print(f"Invalid category IDs found: {set(invalid_categories)}")

import cv2
import random
import matplotlib.pyplot as plt
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog

# Load dataset
dataset_dicts = DatasetCatalog.get("malaria_train")

# Choose a few random images
for d in random.sample(dataset_dicts, 3):
    img = cv2.imread(d["file_name"])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for matplotlib

    # Create a visualizer object
    visualizer = Visualizer(img, MetadataCatalog.get("malaria_train"), scale=0.5)
    out = visualizer.draw_dataset_dict(d)

    # Display image
    plt.figure(figsize=(8, 6))
    plt.imshow(out.get_image())
    plt.axis("off")
    plt.show()

"""#**Exploratory Data Analysis (EDA)**

**Key EDA Tasks:**

**Class Distribution: Plot the distribution of categories.**

**Bounding Box Sizes: Check the distribution of bounding box dimensions.**

**Aspect Ratios: Visualize the aspect ratios of the bounding boxes.**

**Image Sizes: Inspect the distribution of image dimensions.**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the COCO JSON
with open(coco_json_path, "r") as f:
    coco_data = json.load(f)

# Extract category names and bbox sizes
data = []
for ann in coco_data["annotations"]:
    category_id = ann["category_id"]
    bbox = ann["bbox"]

    # Get category name
    category_name = next(cat["name"] for cat in coco_data["categories"] if cat["id"] == category_id)

    # Bounding box dimensions
    width, height = bbox[2], bbox[3]

    data.append({
        "category": category_name,
        "width": width,
        "height": height,
        "aspect_ratio": width / height
    })

# Create DataFrame
df = pd.DataFrame(data)

# 1. Class Distribution
plt.figure(figsize=(12, 6))
sns.countplot(x="category", data=df, palette="muted")
plt.title("Class Distribution")
plt.xticks(rotation=45)
plt.show()

# 2. Bounding Box Width and Height Distribution
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Width Distribution
sns.histplot(df['width'], kde=True, ax=axes[0], color='skyblue')
axes[0].set_title('Bounding Box Width Distribution')

# Height Distribution
sns.histplot(df['height'], kde=True, ax=axes[1], color='orange')
axes[1].set_title('Bounding Box Height Distribution')

plt.tight_layout()
plt.show()

# 3. Aspect Ratio Distribution
plt.figure(figsize=(12, 6))
sns.histplot(df['aspect_ratio'], kde=True, color='purple')
plt.title("Bounding Box Aspect Ratio Distribution")
plt.show()

"""# **Training stage**"""

import os
import requests

# Define the URL and target path for the base config file
base_config_url = "https://raw.githubusercontent.com/facebookresearch/detectron2/main/configs/Base-RCNN-FPN.yaml"
base_config_path = "configs/Base-RCNN-FPN.yaml"

# Ensure the directory exists
os.makedirs("configs", exist_ok=True)

# Define the URL and target path for the Faster R-CNN config file
faster_rcnn_config_url = "https://raw.githubusercontent.com/facebookresearch/detectron2/main/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"
faster_rcnn_config_path = "configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"

# Ensure the directory exists
os.makedirs(os.path.dirname(faster_rcnn_config_path), exist_ok=True)

# Download the Faster R-CNN config file if it doesn't exist
if not os.path.exists(faster_rcnn_config_path):
    response = requests.get(faster_rcnn_config_url)
    if response.status_code == 200:
        with open(faster_rcnn_config_path, "wb") as f:
            f.write(response.content)
        print("✅ Faster R-CNN config file downloaded successfully!")
    else:
        print(f"❌ Failed to download Faster R-CNN config file. HTTP Status: {response.status_code}")
else:
    print("✅ Faster R-CNN config file already exists.")

# Download the base config file if it doesn't exist
if not os.path.exists(base_config_path):
    response = requests.get(base_config_url)
    if response.status_code == 200:
        with open(base_config_path, "wb") as f:
            f.write(response.content)
        print("✅ Base config file downloaded successfully!")
    else:
        print(f"❌ Failed to download base config file. HTTP Status: {response.status_code}")
else:
    print("✅ Base config file already exists.")

print("Faster R-CNN config exists at:", os.path.abspath("configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
print("Base config exists at:", os.path.abspath("configs/Base-RCNN-FPN.yaml"))

import os
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

# Load config
cfg = get_cfg()
cfg.merge_from_file("configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")

# Dataset and model config
cfg.DATASETS.TRAIN = ("malaria_train",)
cfg.DATASETS.TEST = ("malaria_test",)  # Add test dataset for evaluation
cfg.DATALOADER.NUM_WORKERS = 2

cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/ProjectMAL/model_final_280758.pkl"

cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.001
cfg.SOLVER.MAX_ITER = 3000
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # Your 6 malaria classes

# Output directory and checkpoint
cfg.OUTPUT_DIR = "./malaria_frcnn_output"
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
cfg.SOLVER.CHECKPOINT_PERIOD = 1000

# Resume from the last checkpoint
checkpoint_path = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
resume_training = os.path.exists(checkpoint_path)

# Trainer class with custom evaluator
class CustomTrainer(DefaultTrainer):
    @classmethod
    def build_evaluator(cls, cfg, dataset_name, output_folder=None):
        if output_folder is None:
            output_folder = os.path.join(cfg.OUTPUT_DIR, "eval")
        os.makedirs(output_folder, exist_ok=True)
        return COCOEvaluator(dataset_name, cfg, True, output_folder)

# Train the model
trainer = CustomTrainer(cfg)
trainer.resume_or_load(resume=resume_training)

# Save a manual checkpoint at the start
trainer.checkpointer.save("manual_checkpoint")

trainer.train()

# Run evaluation
print("\nRunning Evaluation...")
evaluator = COCOEvaluator("malaria_test", cfg, True, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "malaria_test")
metrics = inference_on_dataset(trainer.model, val_loader, evaluator)

print("\nEvaluation Metrics:")
print(metrics)

import os
import cv2
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog

# Load the trained model config
cfg = get_cfg()
cfg.merge_from_file("configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
cfg.DATASETS.TRAIN = ("malaria_train",)
cfg.DATASETS.TEST = ("malaria_test",)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # 6 malaria classes + 1 difficult class

# Load the final trained model
output_dir = "/content/malaria_frcnn_output"
cfg.MODEL.WEIGHTS = os.path.join(output_dir, "model_final.pth")

# Create predictor
predictor = DefaultPredictor(cfg)

print("\n✅ Final model loaded successfully!")

import json

# Load the metrics.json file
metrics_path = "/content/malaria_frcnn_output/metrics.json"
with open(metrics_path, "r") as f:
    metrics = [json.loads(line) for line in f]

# Display the last recorded metrics
print("\n📊 Final Training Metrics:")
print(metrics[-1])  # Display the last recorded metrics

import json
import matplotlib.pyplot as plt

# Load metrics from the saved file
metrics_file = "/content/malaria_frcnn_output/metrics.json"

# Extract metrics
iterations = []
total_loss = []
cls_accuracy = []
fg_cls_accuracy = []

# Load metrics with synchronized dimensions
with open(metrics_file, "r") as f:
    for line in f:
        data = json.loads(line)

        # Append only if both keys exist
        if "iteration" in data and "total_loss" in data:
            iterations.append(data["iteration"])
            total_loss.append(data["total_loss"])

        # Handle accuracy separately (no dimension mismatch)
        if "fast_rcnn/cls_accuracy" in data:
            cls_accuracy.append(data["fast_rcnn/cls_accuracy"])
        if "fast_rcnn/fg_cls_accuracy" in data:
            fg_cls_accuracy.append(data["fast_rcnn/fg_cls_accuracy"])

# ✅ Plot Total Loss
plt.figure(figsize=(10, 5))
plt.plot(iterations, total_loss, label="Total Loss", color="red")
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.title("Total Loss Over Iterations")
plt.grid(True)
plt.legend()
plt.show()

# ✅ Plot Overall Accuracy
plt.figure(figsize=(10, 5))
min_len = min(len(iterations), len(cls_accuracy))
plt.plot(iterations[:min_len], cls_accuracy[:min_len], label="Overall Accuracy", color="blue")
plt.xlabel("Iterations")
plt.ylabel("Accuracy")
plt.title("Overall Accuracy Over Iterations")
plt.grid(True)
plt.legend()
plt.show()

# ✅ Plot Foreground Accuracy
plt.figure(figsize=(10, 5))
min_len = min(len(iterations), len(fg_cls_accuracy))
plt.plot(iterations[:min_len], fg_cls_accuracy[:min_len], label="Foreground Accuracy", color="green")
plt.xlabel("Iterations")
plt.ylabel("Accuracy")
plt.title("Foreground Accuracy Over Iterations")
plt.grid(True)
plt.legend()
plt.show()

from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer
from detectron2.data import DatasetCatalog, MetadataCatalog
import cv2
import os
import json
import numpy as np

# Load the final trained model
cfg.MODEL.WEIGHTS = "/content/malaria_frcnn_output/model_final.pth"  # Path to final model
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold
predictor = DefaultPredictor(cfg)

# Define paths
image_dir = "/content/drive/MyDrive/Colab Notebooks/ProjectMAL/images"   # Training images folder
json_dir = "/content/malaria_dataset/fixed_training.json"  # Ground-truth annotations folder

# Lists to store ground-truth and predicted values
gt_classes = []
pred_classes = []

# Loop through all images
for image_file in os.listdir(image_dir):
    if image_file.endswith(('.jpg', '.png')):
        image_path = os.path.join(image_dir, image_file)

        # Load image
        image = cv2.imread(image_path)

        # Check if image was loaded successfully
        if image is None:
            print(f"⚠️ Warning: Could not load image: {image_path}")
            continue  # Skip this image

        outputs = predictor(image)

        # Extract predicted classes
        pred_classes.extend(outputs["instances"].pred_classes.cpu().numpy())

        # Extract ground-truth classes from JSON
        json_file = os.path.join(json_dir, f"{os.path.splitext(image_file)[0]}.json")
        if os.path.exists(json_file):
            with open(json_file, "r") as f:
                data = json.load(f)
                for ann in data["annotations"]:
                    gt_classes.append(ann["category_id"])

# Check the number of predictions and ground-truth values
print(f"✅ Ground Truth Labels: {len(gt_classes)}")
print(f"✅ Predicted Labels: {len(pred_classes)}")

import torch
import json
import numpy as np
import detectron2
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from sklearn.metrics import roc_auc_score, recall_score, fbeta_score, mean_squared_error

# **1. Load Config & Model**
cfg = get_cfg()
cfg.merge_from_file("configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")  # Ensure correct path
cfg.MODEL.WEIGHTS = "/content/malaria_frcnn_output/model_final.pth"  # Ensure correct model
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # **Match this with your trained model**
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

predictor = DefaultPredictor(cfg)

# **2. Load Test Dataset**
test_dataset_path = "/content/malaria_dataset/fixed_test.json"

def load_json_dataset():
    with open(test_dataset_path, "r") as f:
        dataset_dicts = json.load(f)
    return dataset_dicts

# **Fix: Check if dataset is already registered before registering**
dataset_name = "malaria_test"
if dataset_name in DatasetCatalog.list():
    DatasetCatalog.remove(dataset_name)  # Remove existing dataset before re-registering

DatasetCatalog.register(dataset_name, load_json_dataset)
MetadataCatalog.get(dataset_name).thing_classes = ["red blood cell", "leukocyte", "gametocyte", "ring", "trophozoite", "schizont", "difficult"]

# **3. Run Predictions & Evaluate**
evaluator = COCOEvaluator(dataset_name, cfg, False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, dataset_name)

coco_eval_results = inference_on_dataset(predictor.model, val_loader, evaluator)
print("COCO Evaluation Results:", coco_eval_results)

# **4. Calculate Other Metrics**
gt_labels = []
pred_labels = []
pred_scores = []

for d in val_loader.dataset.dataset_dicts:
    image = predictor(d["file_name"])
    instances = image["instances"].to("cpu")

    for i in range(len(instances)):
        pred_labels.append(instances.pred_classes[i].item())
        pred_scores.append(instances.scores[i].item())

    gt_labels.extend([ann["category_id"] for ann in d["annotations"]])

# Ensure correct lengths
assert len(gt_labels) == len(pred_labels), "Mismatch in ground truth & predictions length"

# **AUC-ROC Score**
auc_roc = roc_auc_score(gt_labels, pred_scores, multi_class="ovr")
print(f"AUC-ROC Score: {auc_roc:.4f}")

# **Recall Score**
recall = recall_score(gt_labels, pred_labels, average="macro")
print(f"Recall Score: {recall:.4f}")

# **F2 Score (F-beta where beta=2)**
f2_score = fbeta_score(gt_labels, pred_labels, beta=2, average="macro")
print(f"F2 Score: {f2_score:.4f}")

# **RMSE**
rmse = np.sqrt(mean_squared_error(gt_labels, pred_labels))
print(f"RMSE: {rmse:.4f}")
